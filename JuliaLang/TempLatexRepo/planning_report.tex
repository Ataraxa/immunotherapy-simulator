\documentclass[11pt]{article}

\usepackage{amsmath}
\usepackage{amsfonts} % to include additional math. characters such as R
\usepackage{graphicx} % to include images
\usepackage{hyperref} % to be able to click on references
\usepackage{multirow} % to merge cells in tabular env. vertically
\usepackage{subcaption} % for subfigures and +
\usepackage{longtable} % to have table that extends over multiple pages
\usepackage{lipsum}
\usepackage{arydshln} % for dashed lines in tables
\usepackage{color}
\usepackage[parfill]{parskip}
\usepackage[thinc]{esdiff} % for easier d/dx commands
\usepackage[left=2cm, right=2cm, bottom=3cm, top=3cm]{geometry}

% Additional commands
\newcommand*\dif{\mathop{}\!\mathrm{d}}

\graphicspath{ {./Images} }
\title{Cancer Immunotherapy - Planning Report}
\author{Alexandre Y. Péré }
\date{\today}

% What does not count: title page, table of content, abstract, acknowledg.
% tables and figures, appendices, captions, nomenclature and biblio.
% So what counts: section pure content
\begin{document}
\begin{titlepage}
    \newcommand{\HRule}{\rule{\linewidth}{0.5mm}}
    \begin{center}
        \HRule \\[0.4cm]
    { \LARGE \bfseries Bayesian Modelling to Characterise the Responder Profile to a  Novel Cancer Immunotherapy\\[0.55cm] }
    { \large Supervisors: Professor Reiko Tanaka, Dr Tara Hameed} \\
    v2.3
    \\[0.4cm]
    \HRule \\[0.5cm]
    { \large Alexandre Yann Péré \\[0.1cm]
    CID: 01938104  \\[0.1cm]
    \today \\ [0.1cm]
    \vspace{10pt}
    Word Count: 4388ww}
    \end{center}
\end{titlepage}

\tableofcontents


% Repartition of word count (total 4,000)
%
% Project specification (300)
% Litt Review (1,200-1,500)
% Schedule (500)
% Evaluation (300)
% Prelim Results (1,000)
% total=3,000

% QUESTIONS FOR TARA
% 1) What's the difference between GA validation and Bayesian validation??
\pagebreak 
\section{Background}\label{sec:specs}
% This section should state clearly what the project is intended to deliver. It should contain the AIMS, OBJECTIVES and HYPOTHESES of your work.

% Questions/comment: 
% - Should include "optimisation of treament for CR" in aims?
\subsection{Cancer Immunotherapies}
Cancer is a large class of diseases that is the second leading cause of death in the United-States \cite{nchs}. While the immune system has the potential to target and eliminate cancer cells, cancer often finds ways to evade these natural defenses \cite{EvasionMech}. Traditional methods, such as chemotherapy or surgery, rely on using destructive external agents to kill the cancerous cells. However, introducing foreign agents in the body often results in heavy side effects \cite{oncologyTreatRev}. This prompted the development of immunotherapies, a type of treatment aimed at countering cancer's ability to escape immune detection, which thus has the potential to be less toxic. Several viable strategies exist for immunotherapy \cite{ReviewCPI}. We will first review a specific strategy, cytokine-based therapies, as this will enable us to introduce the CBD-IL-12 treatment in the next section, which is the main focus of the project.

Cytokine-based therapies rely on the injection of specific cytokines (small proteins that act as signalling molecules during the immune response) to control tumour growth \cite{ioDef}. One of the most promising cytokine thus far is the interleukin-12 (IL-12), that was shown to have potent antitumour effects \cite{il12IsCool}. While it does not directly affect tumour cells, it mediates the production of other molecules or cells that have a more direct effect \cite{il12CytokineStorm}.
\begin{enumerate}
    \item First of all, it activates the production of tumour-infiltrating cytotoxic cells, mainly CD8$^+$~\cite{cd8FirstWay}. These are a type of T-lymphocytes whose main function is to carry out cytotoxic activity (i.e. killing the malignant cells) after detecting tumoural antigen~\cite{cd8Effects}. 
    \item Secondly, they induce production of another type of cytokine, called interferon-$\gamma$ (IFN$\gamma$) \cite{ifnIL12}. IFN$\gamma$ in turn affects the tumour microenvironment by stimulating production of cytotoxic cells \cite{ifngNKProd}, reducing angiogenesis \cite{ifngAngiogenesis} and upregulating antigen-presenting pathways within tumour cells \cite{ifngAntigenExposure}. It was also discovered by Wang et al., 2000 [cite], that IFN$\gamma$ also in turn increases production of IL-12. This positive feedback loop is called IFN$\gamma$ priming ([cite Liu 2003][cite Ma et al, 2015]).
    \item Lastly, IL-12 facilitates T-cell proliferation (including CD8$^+$) by reducing negative regulatory pathways that lead to immunosuppression \cite{reducImmunoSuppression}.
\end{enumerate}
While these three pathways, illustrated in Fig~\ref{fig:mech}, indicate that IL-12 has a very robust antitumour effect, clinical studies demonstrated that systemic injection of IL-12 is exceedingly toxic as it triggers a large immune response throughout the whole body \cite{clintriAC1}\cite{clintriAC2}. These severe treatment-related adverse effects dampened research about IL-12, waiting for a safer, more localised delivery method to be found.

\begin{figure}
    \centering
    \begin{subfigure}{.49\textwidth}
        \centering\includegraphics[scale=0.3]{immune_resp.png}
        \caption{}        
    \end{subfigure}
    \begin{subfigure}{.49\textwidth}
        \centering\includegraphics[scale=0.3]{control_process.png}    
        \caption{}
    \end{subfigure}
    \caption{\textbf{(a)} Illustration of the action mechanisms of IL-12-based cytokine (such as CBD-IL-12). Processus included in the model are: (1) IL-12-induced production of IFN$\gamma$ by T-cells, (2) upregulation of CD8$^+$ T-cells proliferation by IL-12, (3) down-regulation of the PD-1 immunosuppressive pathway, (4) IFN$\gamma$-triggered production of IL-12 by dendritic cells, (5) reduced proliferation of tumour cells through suppressed angiogenesis and (6) CD8$^+$-mediated cytotoxic activity.\\
    \textbf{(b)} ha}
    \label{fig:mech}
\end{figure}
\subsection{A novel immunotherapy: CBD-IL-12}
Recent endeavours in this field of immunotherapies led to the development by Ishihara group at Imperial College in 2019 \cite{cbdil12} of a new molecule, CBD-IL-12, that demonstrated promising results to treat melanoma. We first review how CBD-IL-12 works, and then we detail the experimental results obtained by the lab. 

The CBD-IL-12  molecule consists of a collagen-binding protein (or collagen-binding domain, CBD) that is fused onto a IL-12 cytokine. The modified interleukin hence mainly accumulates in collagen-rich regions. As collagen is the main component of cancerous microenvironment \cite{collagenInCancer}, this effectively results in an enhanced delivery method that can achieve high concentration of IL-12 specifically in cancerous microenvironments, which helps decreasing the toxicity of the treatment.

To measure treatment efficacy on cancer, a common metric is the complete response (CR) rate among patients \cite{cancMetric}. CR corresponds to the disappearance of all known lesions \cite{CRDef} in the long run (steady-state). Since the optimal delivery method for CBD-IL-12 is not known, the authors measured the CR-rate in various settings: injection on day 7, or on day 9, in combination with other drugs or not, etc. For this project, we focus on the specific case of CBD-IL-12 monotherapy (no other drugs are being used) injected on day 7, since this is the setting for which we have the most comprehensive set of data. For this treatment protocol, nine mice were inoculated a skin tumour on day 0. Tumour volume was then recorded at specific time points until day 27. Fig.~\ref{fig:outcomedual} plots these tumour volume evolution for each individual mouse. Tumour is successfully inhibited in all mice at different rates, up to day 20. At this point, two mice exhibited a resurgence of tumour growth, while for the remaining ones the tumour stayed inhibited (below 1mm$^3$) until the end of the experiments (day 27). We can conclude that, for this period of time at least, seven out of the nine mice experienced CR, resulting in a CR-rate of 77\%.

\begin{figure}[!ht]
    \centering\includegraphics[scale=0.3]{crnoncr2.png}
    \caption{Evolution of tumour volume over time for a batch of mice shows that they present two distinct behavours: CR or non-CR (each trace is an individual mouse)}
    \label{fig:outcomedual}
\end{figure}

This heterogeneity of response (CR vs non-CR) could not be explained by the authors, and highlights the need to further analyse available data in order to identify the key biological parameters that can help differentiate the diverging responses.

\subsection{Data Analysis with the Aid of Computational Modelling}\label{ssec:prevWork}

To have a better understanding of the immune response to CBD-IL-12, Dr Miyano, a previous member of the Tanaka group \cite{takuya}, proposed to use a computational modelling approach. Computational models are common in pharmacodynamics as they can be analysed with mathematical tools, potentially revealing key mechanisms to optimise the treatment. He developped an initial mechanistic model based on Delay-Differential Equations (DDEs), parameterised by 21 parameters representing various relevant biological factors of a given mouse, such as the tumour growth rate or the degradation rate of IFN$\gamma$ \cite{takuya}: 
\begin{align*}
    \dot{g}(t) &= k_1 + k_2 [d_{CBD}(t) + d_{12}(t)] - d_1g(t) \\ 
    \dot{c}(t,t-t_d) &= k_3 + k_4g(t-t_d)-d_2c(t) \\ 
    \dot{p}(t) &= k_5 - [d_3 + d_4g(t)]p(t) \\ 
    \dot{v}_l(t) &= k_6\left[1 - \frac{v(t)}{v_{max}} \right]v_l(t) - \left[d_5 + \frac{\frac{d_6c(t)}{1+s_1p(t)(1-d_{CPI}(t))}+d_7g(t)}{1+s_2v(t)}\right]v_l(t)\\
    \dot{v}_d(t) &= \left[d_5 + \frac{\frac{d_6c(t)}{1+s_1p(t)(1-d_{CPI}(t))}+d_7g(t)}{1+s_2v(t)}\right]v_l(t) - d_8 v_d(t)
\end{align*}
The five state variables ($g$, $c$, $p$, $v_l$ and $v_d$) are concentration of IFN$\gamma$, of CD8$^+$ and of PD1 along with volume of living and dead tumour, respectively. This was motivated by the fact that these are the key players in the immune response, as explained above. The meaning of each parameter is reported in the Appendix~\ref{app}. These equations are the mathematical formulation of the relations illustrated in Fig.~\ref{fig:cell}, except for the IFN$\gamma$ priming loop, which was not included in the initial mechanistic model.

The parameters of this mechanistic model all represent biological factors that could potentially be responsible for the diverging treatment outcomes. However, these parameters are kinetic rates that cannot be measured experimentally: they can only be estimated from observable data, i.e. tumour volume. This process, called parameter estimation, was investigated and applied to the mechanistic model by Hines, another previous member of the Tanaka group. However, naive parameter estimation can only work to extract parameter from one single time series, and hence cannot be directly applied to the collection of times series obtained by the lab. Hines' approach was to fit the average curve [add figure] to the mechanistic model. This resulted in a set of parameters that can explain (i.e., reproduce) this average behaviour. However, Hines concluded in his report that this set of parameter was not sufficient to help differentiating the different drug responses, as it can only reproduce an average curve that in essence represents neither a CR outcome nor a non-CR outcome.

Hines' conclusion motivates to use alternative parameter estimation methods that could help us identify the key biological factors that differentiate between CR and non-CR, by taking into account the whole dataset obtained in the lab. To this end, we first note that there is some shared information between the mice, since they are all sampled from the same population, as well as some variability between that explain the range of output obtained in the lab. Nonlinear mixed-effects models \cite{Davidian2011} are a standard method to analyse population dataset with both shared information (called fixed-effects) and individual variability (called random-effects). This is further detailed in Section~\ref{sec:littrev}.

\section{Aims and Objectives}
\noindent The aim of this project is verify whether Takuya's mechanistic model can be extended to identify the biological factors that can differentiate between CR and non-CR.\\[8pt]
\textbf{Objective 1:} develop a computational mixed-effect model that can reproduce the experimental data.\\ 
\textbf{Objective 2:} compute the distributions of the model parameters and verify whether they are bimodally distributed.\\ 
\textbf{Objective 3:} evaluate the impact of the IFN$\gamma$ priming pathway on the treatment outcome. 
% \textbf{Objective 3:} associate key factors to potential biomarkers in mice\\ 
% \textbf{Objective 3:} understand how the boundary between CR and non-CR depends on the treatment characteristics (number and frequency of doses, combination with other treaments, etc.)

\section{Ethical Analysis}
%This should be a short section. Mention the ethical basis, background, and implications of the project regarding subjects and specimens used and their provenance, data derived or measured and their use. Include the long-term effects and meaning of the work, as well as the effects of the work on colleagues, the College, society and the environment as appropriate.

Treatments and experiments on the specimens used, mice in this case, were approved by the Institutional Animal Care and Use Committee of the Univerity of Chicago (see Methods section of \cite{cbdil12}).

The data derived from these experiments holds potential for understanding treatment response in cancer, aiding in the optimization of therapies for human use. Long-term implications involve the potential for groundbreaking advancements in cancer treatment, benefiting society globally. As this concerns development of drugs for human use, it is necessary to develop a robust work ethics that avoid developing harmful therapies to human. Thus, to ensure that the results are reliable and can be reproduced by anyone, the full analysis along with the code will be published on GitHub.
% \pagebreak

\section{Literature Review on Parameter Estimation}\label{sec:littrev}

As mentioned in Section~\ref{sec:specs}, the project requires a parameter estimation method that can be applied to mixed-effects models. In this section, we first give a more rigorous definition of the parameter estimation along with an overview of the different methods available. We then review a specific method, called hierarchical Bayesian modelling, and highlight its particular relavance to the project. 

\subsection{Definition and Notation}
Let the general definition of a DDE model be: 

\begin{align*}
    \diff{X_i}{t} = f_i(t, \boldsymbol{X}(t), \boldsymbol{X}(t-\tau)| \boldsymbol{\theta}), \qquad t \in [t_0, t_{max}], i = 1, \ldots, I
\end{align*}

where $\tau$ denotes a constant delay, so that the rate of change of state $X_i$ depends on both the present state $\boldsymbol{X}(t)$ and a past state $\boldsymbol{X}(t-\tau)$. The subscript \textit{i} indexes the different state variables of interest, and $\boldsymbol{\theta}$ is the (unknown) vector of the parameters for the DDE model. This parameter vector is different for each treated mouse, as it uniquely characterises its treatement response, and hence we denote with $\boldsymbol{\theta}_j$ the parameter vector that characterises the $j$-th mouse. The experimentally observed tumour evolution for the $j$-th mouse is denoted by $\boldsymbol{y}_j$, and each of its elements is the tumour volume observed at a given time, noted $y_{j}(t)$. The aim of parameter estimation is to retrieve the parameter vector that can reproduce the observed data. Mathematically, this can be expressed as maximising the likelihood of the observations $\mathcal{L}(\theta;\boldsymbol{y})$, where $\eta_j$ is the random effect for individual $j$ \cite{SAEM}. 
\begin{align*}
    \mathcal{L}(\boldsymbol{\theta};\boldsymbol{y})=\prod_{j} \mathcal{L}(\theta;\boldsymbol{y}_j)=\prod_j p(\boldsymbol{y}_j\vert \boldsymbol{\theta})=\prod_j \int p(\boldsymbol{y}_j\vert \eta_i,\boldsymbol{\theta})p(\eta_j\vert \boldsymbol{\theta}) \,d\eta_j
\end{align*}

Many statistical approaches have been developed to perform parameter estimation on differential equation models from noisy data \cite{liu_wang}. However, most of them cannot be applied to mixed-effect models. In the context of pharmacodynamics model , Donnet et al, 2013 \cite{revParamEst} reviewed different techniques available to perform parameter estimation. For analysis of population data with observational noise, only two methods are available: Expectation-Maximisation (either Stochastic \cite{SAEM} or using First-Order Condition \cite{foce}) and Bayesian parameter estimation \cite{rosenbaum}. The authors concluded that Bayesian modelling in particular is the most flexible method, since it does not rely on assumptions and hence work for both individual or population datasets, with or without noise, which is not the case for alternative methods. Additionally, it benefits from theoretical validity although at the cost of being more computationally intensive, whereas the First-Order Conditon method was not proven to always converge to the true posterior. Another relevant advantage is that Bayesian approach do not provide point estimate, but rather distributions, which could be key to explain outcome heterogeneity. Hence the Bayesian modelling approach seems to be the most relevant for the project. 

\subsection{Bayesian Parameter Estimation}

Bayesian Parameter Estimation is a method to estimate $\boldsymbol{\theta}_j$ given an observation vector $\boldsymbol{y}_j$. Contrary to frequentist approach, estimations are in the form of probability distributions (called posteriors, denoted $p(\boldsymbol{\theta}|\boldsymbol{y})$) rather than point estimates. 

For a situation where data about only one individual was gathered, the posterior distribution is defined as follows \cite{tbk_gelman}:
\begin{align*}
    p(\boldsymbol{\theta} | \boldsymbol{y}) \propto p(\boldsymbol{\theta})p(\boldsymbol{y}|\boldsymbol{\theta})
\end{align*} 
This formula is the direct application of Bayes' theorem. It is the product of the prior distribution $p(\boldsymbol{\theta})$, which represents our knownledge of the problem, and the likelihood $p(\boldsymbol{y} | \boldsymbol{\theta})$. Before further defining these distributions, we must extend this definition of the posterior distribution to work for mixed-effect models, called hierarchical models in Bayesian statistics. 

\subsection{Hierarchical Modelling}
We seek to estimate the probability distribution of the parameter vector $\boldsymbol{\theta}$ for each individual, however these vectors are not independent from each other since each individual is sampled from a common population (mixed-effect model). To analyse mixed-effect model, hierarchical Bayesian modelling is a standard method \cite{revParamEst}\cite{rosenbaum}. For example, Rosenbaum et al., 2019 \cite{rosenbaum}, studied models of predator-prey systems, which also display radically different behaviours depending on the values of certain kinetic rates that cannot be directly measured. By fitting times series of measurable data to a hierarchical Bayesian model, they could not only extract a specific set of parameters for each individual system; but also determine the regions in parameter space that led to radically different types of behaviour accross the population. As this study present many similarities with the current project, it shows that hierarchical Bayesian modelling is a promising tool that is worth exploring.

Hierarchical modelling enables us to formulate that the parameter vector $\boldsymbol{\theta}_j$ is sampled from an population-level distribution characterised by the (also unknown) hyperparameters $\boldsymbol{\phi}$. The objective is hence to find the distribution of both $\boldsymbol{\theta}_j~\forall j$ and $\boldsymbol{\phi}$. The Bayesian parameter estimation framework integrates this additional assumption by changing the posterior to \cite{tbk_gelman}:
\begin{align*}
    p(\boldsymbol{\theta}, \boldsymbol{\phi} | \boldsymbol{y}) \propto p(\boldsymbol{\phi})p(\boldsymbol{\theta}|\boldsymbol{\phi})p(\boldsymbol{y}|\boldsymbol{\theta})
\end{align*} 

This expression is a product of the hyperprior $p(\boldsymbol{\phi})$, the population distribution $p(\boldsymbol{\theta}|\boldsymbol{\phi})$ and the likelihood $p(\boldsymbol{y}|\boldsymbol{\theta})$.

\subsubsection{Hierarchical Priors and Hyperpriors}
In hierarchical Bayesian models, there are two types of parameters: hyperparameters $\boldsymbol{\phi}$ and individual parameters $\boldsymbol{\theta}_j$ \cite{tbk_gelman}. The key feature is that the simulated data is directly conditioned on the regular parameters, which are themselves drawn from population-level distributions characterised by hyperparameters. Hence, this results in two types of priors: hierarchical priors, that specify how to sample $\boldsymbol{\theta}$ using the hyperparameters $\boldsymbol{\phi}$; and hyperpriors that convery our knowledge about the potential values of~$\boldsymbol{\phi}$.

For the case of Bayesian parameter estimation on sets of time series, Rosenbaum et al, 2019 \cite{rosenbaum}, proposed to sample each ODE parameter from a Normal distribution. As Normal distribution are characterised by two values (mean $\mu$ and standard deviation $\sigma$), this resulted in two hyperparameters per ODE parameter. This can be summarised as follows, for a given scalar parameter $\theta$:
\begin{align*}
    \theta &\sim p(\theta | \phi) \Leftrightarrow \theta \sim \mathcal{N}(\phi_\mu, \phi_\sigma) \quad &&\textit{hierarchical prior} \\ 
    \phi_\mu &\sim p(\phi_\mu) \quad &&\textit{hyperprior for the hyper-mean} \\ 
    \phi_\mu &\sim p(\phi_\mu) \quad &&\textit{hyperprior for the hyper-standard deviation} 
\end{align*}
By adding additional hyperparameters, this definition could be modified to allow for bimodal distribution instead of a simple normal distribution for the hierarchical priors.

\subsubsection{Likelihood function}
The likelihood function in the Bayesian framework is how we model the dynamics of the underlying process. In pharmacodynamics, it is the mechanistic model of the immune response. Assuming that the observational noise is a white Gaussian noise with zero-mean and a standard deviation $\sigma_{err}$ that is common to all experiments, the likelihood can then be defined as follows \cite{liu_wang}\cite{likelihood_2} (for a given tumour evolution $\boldsymbol{y}_j$):
\begin{align*}
    \mathcal{L}(\boldsymbol{\theta}_j) = \prod_{t=t_0}^{t_{max}} \frac{1}{\sigma_{err}} \exp\left(-\frac{(y_{j}(t) - Y_j(t|\boldsymbol{\theta}_j))^2}{2\sigma_{err}^2}\right)  
\end{align*}
Where $Y_j(t|\boldsymbol{\theta}_j)$ is the simulated time series using the DDE model parameterised by $\boldsymbol{\theta}_j$, $t$ is the time index for the time series and $\sigma_{err}$ is the experimental error. This is usually obtained by numerical methods. Without additional information about the measurement methods, this is the approach suggested by Rosenbaum et al \cite{rosenbaum}.

% \subsubsection{Calcultion of the Marginal Posterior Distributions}\label{ssec:post}
% Once the joint posterior distribution has been obtained, we can proceed to calculate the marginal probability densities for $\theta_j \forall j$ and for $\boldsymbol{\phi}$ \cite{tbk_gelman}.

% First, we calculate the joint posterior distribution conditional on each time series individually, ie:
% \begin{align*}
%     p(\theta_j,\phi|y_j) = p(\phi) \mathcal{B}(\theta_j|\phi) \mathcal{L}(\theta_j)
% \end{align*}

% We can then calculate each individual marginal probability density (ie. for each vector $\theta_j$) as:
% \begin{align*}
%     p(\theta_j|y_j) = \int p(\theta_j, \phi|y_j) \dif \phi 
% \end{align*}


% To find the marginal posterior distribution for the hyperparameter vector $\boldsymbol{\phi}$, we can marginalise out $\theta$ by integrating over $\theta$ the full joint posterior distribution (ie. accross all time series):
% \begin{align*}
%     p(\phi|y) = \int \prod_{j=1}^{J} p(\theta_j, \phi|y_j) \dif \theta 
% \end{align*}

\subsection{Reduction of the Computational Burden}
\subsubsection{Sensitivity Analysis}
As pharmacodynamics models can generally contain a high number of parameters, the Bayesian approach, which is computationally intensive \cite{revParamEst}, can result in intractable computations. To this end, Vasquez-Cruz et al, 2012 \cite{tomgro}, proposed a method to reduce the number of parameters in an ODE model. By taking the example of a crop growth ODE model with 17 parameters, they used a senstivity analysis (namely, eFAST and Sobol' method) to identify the most influencial parameters, and used these results to design a reduced model with only 7 free parameters. All the other parameters with a negligible influence were seet to a fixed value. Then, using a parameter fitting algorithm, they were able to show that this reduced model could still replicate the experimental data with minimal error. Additionally, they showed that the two sensitivity analysis methods (eFAST and Sobol' methods) yield different results. Hence, to ensure that all the important parameters are detected, both methods should be used.

\subsubsection{High-performance Computational Methods}
As the estimation of the posterior distributions cannot be evaluated analytically, Luengo et al., 2020 \cite{MCMethods}, pointed out that Markov-Chains Monte Carlo approach to approximate the posterior is the only feasible approach in most applications. While many different MCMC methods exist \cite{ReviewMCMCAlgo}, it was shown by Nishio et al, 2019 \cite{NUTSvsHMCvsGibbs} that the No U-Turn Sampler (NUTS) led to lower skewness of the posterior and more decorrelated samples compared to the other two popular algorithms, Gibbs and Hamiltonian Monte Carlo samplers. However, traditional MCMC methods, including NUTS, can have convergence problem \cite{mcmcTrapped}. Since we hypothesised that the posterior distribution might be multimodal, we need also need a robust sampler for this case. Liu et al, 2018 \cite{liu_wang}, proposed a new sampler called Stochastic Approximation Monte Carlo (SAMC), which is based on the idea of partitioning the parameter space in a finite number of subspaces and forcing the algorithm to explore each subspace. By running the algorithm on a parameter estimation problem for an ODE model of predator-prey system (defined in \cite{fussmann}), they showed that SAMC could successfully retrieve the correct parameter value, while traditional MCMC methods such as the Metropolis-Hastings method were stuck in local modes.

\subsubsection{Transforms}
Another finding from the study of predator-prey systems \cite{rosenbaum} is that log-transformation of the residuals make the inference much more robust, resulting in faster convergence and more accurate posteriors. This changes the likelihood function to the following:
\begin{align*}
    \mathcal{L}(\boldsymbol{\theta}_j) = \prod_{t=t_0}^{t_{max}} \frac{1}{\sigma_{err}} \exp\left(-\frac{\lbrack\ln(y_{j}(t)) - \ln(Y_j(t|\boldsymbol{\theta}_j))\rbrack^2}{2\sigma_{err}^2}\right)  
\end{align*}

% Question for Tara: what if the revised mechanistic model does not capture the dual outcome that is initially present? Does that mean the model is wrong, or that the dual outcome is not exactly accurate?

% In light of the knowledge gathered through the litterature review presented above, the proposed plan to fulfill the 4 (3?) objectives is as follows.\\[12pt]
% %
% \noindent\textbf{Task 1.1 -- Evaluation of the initial model (already completed)}\\
% This includes numerical stability/bifurcation analysis and sensitivity analysis to find the boundary between CR and non-CR in parameter space. This step is necessary to understand to general design principles that guide the development of a mechanistic model, and can potentially reveal some of the model weaknesses that need to be addressed. The sensitivity analysis is also key to reduce the dimensionality of the problem, since the model is otherwise too large and would result in intractable computations.\\[12pt]
% %
% \noindent\textbf{Task 1.2 -- Non-hierarchical model validation (already completed)}\\ 
% The second step is to verify whether the model can be used to perform Bayesian inference, as this will be the core of the analysis. Following the procedure highlighted  in the \textit{Bayesian Workflow} paper by Gelman et al., 2020, \cite{gelman2020bayesian}, the validation consists of three main tests: prior predictive check, fake data check and posterior predictive check. In Task 1.2 we will focus on validating complete- and no-pooling models since they are the basic blocks that we will use in Task 1.3 to construct the full hierarchical model.\\[12pt]
% %
% The above validation procedure might fail in two ways : either the model cannot produce results (for example, the MCMC chains cannot explore the posterior distribution well), or it produces wrong results. For each outcome, we present below the steps we plan to take to overcome these.\\[12pt]
% %
% \noindent\textbf{Task 1.2a (fall-back 1) -- Validate using Approximate Bayesian Computation (2-3 weeks)}\\ 
% In the event that the MCMC chains do not converge, it would be due to the high complexity of the likelihood function (the mechanistic model of the immune response), a set of five Delayed Differential Equations that cannot be solved analytically. One way to reduce this complexity would be to use Approximate Bayesian Computation (ABC), which is a likelihood-free framework \cite{ABCtuber}. This approach is a  realitvely easy to implement method that prevents convergence problems, at the cost of slightly less exact results. \\[12pt]
% %
% \noindent\textbf{Task 1.2b (fall-back 2) -- Validate using simplified likelihood function (3 weeks)}\\
% As suggested in the \textit{Bayesian Workflow} paper \cite{gelman2020bayesian}, another method to solve convergence issues would be to simplify the likelihood function, for example by using ODEs instead of DDEs. This is an alternative to ABC, and would require more time to implement as we need to completely review the tumour model. However, contrary to ABC, it is still a traditional Bayesian inference and hence results in less approxmation errors, as highlighted by Robert et al, 2011 \cite{ABCerror}\\[12pt] 
% %
% \noindent\textbf{Task 1.2c (fall-back 3) -- Modify the model (1 month)}\\ 
% In the event that the inference can be run but produces wrong results, the most sensible approach would be to modify the Bayesian model. Care will be taken to ensure that all the key interactions during the immune response are correctly translated into the mechanistic model. The first missing pathway that we plan to implement is the positive feedback loop mentioned in Section~\ref{sec:littrev}. During this process, we expect to use a Genetic Algorithm for parameter fitting. This will be useful to test that the mechanistic model can reproduce the data, without having to resort to a full Bayesian inference, where many additional elements interact together and can make precise diagnostic harder. \\[12pt] 
% %
% \noindent\textbf{Task 1.3 -- Validation of the hierarchical model (3 weeks)}\\ 
% We will validate the hierarchical model once its two components are verified (no-pooling and complete-pooling models) through Task 1.2. It is still a Bayesian model, so we plan to follow the same validation procedure as above (including the fall-backs)\\[12pt]
% %
% \noindent\textbf{Task 2.1 -- Extensive numerial analysis of the compuational model (1-2 weeks)}\\ 
% This is the first set of analysis we plan to do on the validated model. This includes a eFAST sensitivity test, which enables us to reduce the dimensionality of the problem. This makes practical implementation of the subsequent analysis possible, while minimising the error we introduce. Following this, we will perform a stability analysis to evaluate the boundary surface in parameter space that separates CR from non-CR. We expect a grid-search analysis to be sufficient, since w are only concerned with the location of the bifurcation point.\\[12pt]
% %This is the first set of analysis we plan to do on the validated model. First we perform a sensitivity analysis, using the eFAST method as justified in Section~\ref{sec:background}. This is necessary to know if a given parameter should be set as a free or fixed parameter. This makes practical implementation of the subsequent analysis possible, while minimising the error we introduce. Then, we plan to perform a bifurcation analysis to evaluate the boundary surface in parameter space that separates CR from non-CR. We expect a grid-search bifurcation to be sufficient, since only trans-critical bifurcation can happen (Hopf would not make biological sense... ?). \\[12pt]
% %
% \noindent\textbf{Task 2.1a (fall-back 1) -- ?}\\ 
% (What happens if the model does not capture the bifurcation behaviour? Does it mean that the model is wrong?) \\[12pt]
% %
% \noindent\textbf{Task 2.2 -- Full Bayesian Inference (3 weeks)}\\ 
% In this step we perform a full hierarchical Bayesian inference and analyse the posterior distributions to find patterns that could explain data heterogeneity. It is still unclear what type of patterns it would be, but we suspect that the posterior distributions might be bimodal, which explains the bimodal treatment outcome. Bimodal posterior could reveal the bifurcation point between CR and non-CR, which is key for the next step. Task 2.1 ensures that such a bifurcation point exists. \\[12pt]
% %
% \noindent\textbf{Task 3 -- Biomarker Identification}\\ 
% Having identified the key parameters that encode the outcome heterogeneity along with their bifurcation point, we will link each of them to a corresponding mouse biomarker. We suspect that the exact methodology will depend on which parameters are selected for this step, but we propose to follow to general methodology for biomarkers identification presented in Section~\ref{sec:background}, relying on genomic data and statistical tools. We will also make use of the already-existing litterature about cancer biomarkers that measure potential response to therapy. \\[11pt]
% %
% \noindent\textbf{Task 3.a (fall-back 1) -- Collect genomic data}\\ 
% If genomic data is not available, means that we will have to collect it first. It is likely that the project will thus not be finishable, so will only be able to design computational/theoretical framework for biomarker identification without practical implementation.  

\section{Risk Register}
The risks associated with the project along with a mitigation plan are described in Table~\ref{tbl:hyperparams}

\begin{table}[!ht]
    \caption{Table of the different risks associated with the project's objectives}

    \label{tbl:hyperparams}
\begin{longtable}{|p{3.5cm}|p{2.3cm}|p{2.3cm}|p{8cm}|}
    \hline
    \textbf{Risk} & \textbf{Likelihood} & \textbf{Impact} & \textbf{Mitigation Strategy}\\
    \hline
    \endfirsthead
    \hline
    \textbf{Risk} & \textbf{Likelihood} & \textbf{Impact} & \textbf{Mitigatio Strategy}\\
    \hline
    \endhead
    \hline
    \multicolumn{4}{|r|}{\textit{Continued on next page}} \\
    \hline
    \endfoot
    \hline
\endlastfoot
        \hline
        MCMC chains do\newline not converge  & High & Very high & 
        Two alternative methods can be used in this case.
        \textbf{Approximate Bayesian Computations,} which is a approach that does not rely on a likelihood function. It is relatively easy to implement but introduces additional approximation error. \textbf{Model simplification}, an approach proposed in \cite{gelman2020bayesian}. It consists of simplifying the likelihood function, and does not introduce additional error.
        \\ \hline 
        Model does not\newline pass validation protocol& High & Very high & Modify the immune response model to ensure that all key interactions are translated in the mechanistic model. We especially plan to implement the positive feedback loop mentionned in Section~\ref{ssec:prevWork}. \\ \hline 
\end{longtable}
\end{table}
\section{Evaluation}\label{sec:eval}
\textit{Objective 1: Bayesian Model}\\[3pt]
    The first objective of the project is to design a hierarchical Bayesian model. To validate it and proceed to the next objective, we will follow the validation procedure outlined in \cite{gelman2020bayesian}. It consists of three different tests that must each be passed:
\begin{itemize}
    \item \textbf{Prior Predictive Check:} we sample 1,000 sets of parameter from the priors and simulate tumour growth for each of them. The 95\% credible interval of the resulting collection of time series should contain our expected range of curves we can expect, otherwise the test is not passed.
    \item \textbf{Fake Data Check:} we first need to generate a artificial dataset using known values of parameters, and then fit the Bayesian model to these fake datasets. If the 95\% credible interval of the posterior distributions each include the corresponding true parameter value, then the model passes the test.
    \item \textbf{Posterior Predictive Check:} this is analogous to the prior predictive check, except that parameter are drawn from the marginal posterior distributions instead of the prior distributions. This results in a collection of simulated time series. The criterion for the model to pass the test is that the 95\% credible interval should contain the experimental time series obtined in the lab. 
\end{itemize}
% \textit{Convergence of the MCMC Chains}\\[3pt]
% As mentioned above, convergence of the MCMC chains is a critical element that needs to be evaluated, as it reflects the quality of the approximation of the posterior distribution \cite{moins2023use}. The most popular method to assess convergence is the potential scale factor reduction, usually termed $\hat{R}$, developed by Gelman et al., 1992 \cite{rhat}. It can be calculated as follows:
% \begin{align*}
%     \hat{R} &= \frac{m+1}{m}\frac{\hat{\sigma}^2_+}{W}-\frac{n-1}{mn} \\ 
%     W &= \frac{1}{m(n-1)}\sum^m_{j=1}\sum^n_{t=1}(\psi_{jt}-\bar{\psi}_j)^2 
% \end{align*}
% Where $m$ is the number of chains used to explore the posterior in parallel, $n$ is their length, $\hat{\sigma}^2_+$ is the variance of the chain with the highest variance, $\psi_{jt}$ is the value of the $j$-th chain at the $t$-th iteration, and $\bar{\psi}_j$ the mean value of the $j$-th chain. The authors additional highlight that a value close to 1 usually indicates convergence, usually the criterion is $\hat{R}<1.05$ for convergence.

\textit{Objective 2: Responder Profile}\\[3pt]
For objective 2, through the validated bayesian model we will (1) identify the parameters that can differentiate responders from non-responders; (2) define the range of values of each of the parameters to differentiate CR from partial responders and non responders. To do so, we will compute the posterior distribution of the hypermean for two datasets: one with only CR data, and one with only non-CR data. If the mean of the posterior distributions are significantly different (they are not within the 95\% credible interval of each other), we can conclude that the Bayesian version of the mechanistic model can successfully help us differentiating between CR and non-CR by identifying the key biological factors. An asparational outcome would be to identify one or more biomarkers, e.g., PD-1, whose presence and/or its concentrations at given timepoints post intervention can reflect the responder profile parameters, hence has predictive value for future studies.

\textit{Objective 3: Impact of IFN$\gamma$ priming}
To evaluate the impact of the IFN$\gamma$ priming feedback loop, we will first modify the Bayesian model to include it. Once it has been validated following the same procedure as highlighted above, we will construct a new responder profile and compare it with the previously obtained profile (that does not include the feedback loop). If in each case different key parameters were identified, this means that IFN$\gamma$ cannot be neglected and needs to be included in the model.

\section{Preliminary Results}

\subsection{Numerical Stability Analysis}

The very first aspect of Miyano's model that we wanted to verify was its ability to capture two specific treatment outcome: CR vs non-CR. As these behaviours can essentially be characterised by the fixed-points of the model (if the steady-state behaviour of the model converges to high values of tumour volume, it is a non-CR behaviour, and vice-versa. See definition in Section~\ref{sec:specs}). We opted for a grid-search stability analysis, meaning that we sample reguarly-spaced points in parameter space and classify them as either CR or non-CR. Fig.~\ref{fig:mcsa} shows the resuls of this analysis, where each axis of the cube corresponds to the value of a $k_6$, $s_2$ or $d_1$ respectively. A can be seen, there seem the be a clear boundary between the two response modes, with very little ``mixing''. This suggests that it would be possible to predict how a given patient would respond to the treatment, by knowning on which side of the boundary he is.

\begin{figure}[!ht]
    \centering\includegraphics[scale=0.5]{stability.png}
    \caption{Stability analysis shows that there is a clear boundary in parameter space between CR and non-CR}
    \label{fig:mcsa}
\end{figure}

\subsection{Sensitivity Analysis}
In order to restrict the parameter space for subsequent analysis, and also to understand to main mechanisms behind the immune response, we performed a eFAST sensitivity analysis, which is a variance decomposition method. As it can only decompose variance of a scalar metric, it does not natively support time-series. Hence we chose to apply it to the integral of the tumour growth curve simulated by Miyano's model. This metric simply reflects the cumulative tumour volume over time, which is ultimately the quantity that we want to minimse. Other metrics which capture more specific feature of the tumour growth might be considered in the future, such as the derivative of tumour growth on the last simulated day to capture the patient's potential to go into CR. Results are shown in Fig.~\ref{fig:efast}. The total height of the bar represent the fraction of the variance that is imputable to the corresponding parameter. The first observation we can make is that model is mostly sensitive to $k_6$, $d_1$, $d_7$ and $s_2$. However, we can see that the main effect indices (in blue, corresponding to the direct effect of the parameter on the model) are almost always negligible compared to the total-order indices (in orange, which considers both the direct impact as well as combined interaction with other parameters). According to a study by Vazquez-Cruz et al. (2012), this is a typical sign of non-identifiability \cite{tomgro} that will significantly hinder Bayesian inference. Additionally, results indicate that the treatment characteristics (labelled \verb+t_d+, \verb+t_delay+ and \verb+t_last+) have almost no impact on the treatment outcome, which is conflicting with the results experimentally obtained in the CBD-IL-12 study \cite{cbdil12}. Hence we suspect that the current model does not correctly model the immune response mechanisms. 

\begin{figure}[!ht]
    \centering\includegraphics[scale=0.07]{proutiprouta.png}
    \caption{eFAST sensitivity analysis on Miyano's model shows that $k_6$ is the most influencial parameter by far, followed by $d_1$, $d_7$ and $s_2$. This is conflicting with findings from Ishihara group}
    \label{fig:efast}
\end{figure}

\subsection{Bayesian Model Validation}
In this section we show how the Bayesian model was validated, following the procedure highlighted in Section~\ref{sec:eval}. We focus on a reduced model with only three free parameters, $k_6$, $d_1$, $s_2$, which were identified by C.~Hines are the most impactful ones \cite{christian1}. All other parameters of the model were fixed to their respective value estimated by C. Hines to model the mean response curve. This ensures that each parameter is assigned a realistic yet arbitrary value.

\subsubsection{Prior Predictive Check}
In this case, we do not have much data on the typical values of the parameters since it is impossible to measure it (we only know that it is a positive number whose typical value is between 0 and 1, as evidenced by \cite{christian1}), so we aim to design an uninformative prior. Fig.~\ref{fig:ppc_1} shows a plot of 1,000 tumour growth time-series. Each of them was simulated using a set of parameters drawn from the following prior distribution:
\begin{align*}
    \ln(k_6) \sim \text{Cauchy}^-(0, 1) \\ 
    \ln(d_1) \sim \text{Cauchy}^+(0, 1) \\ 
    \ln(s_2) \sim \text{Cauchy}^-(0, 1) \\ 
\end{align*} 
We chose Cauchy distributions since that carry less information that standard Gaussian distributions, allowing for value far from their center of mass. This is critical since we do not have information about the true values of the parameters. As we exponentiate the Cauchy distribution, it means that $0 < k_6 < 1$. The blue shade represents the 95\% credible interval, and the dark green line is the median growth curve. As we can see, the 95\% credible interval is can virtually contain our expected range of curves, since it ranges from 0 (minimum volume) to 600 (maximum possible volume according to the equation), meaning that they are relatively uninformative priors. The median curve has the shape of the typical growth curve, as observed in the labs. Hence, we can say that the prior distribution is satisfying, as it could explain any potential growth curve while restricting the values of the parameters to a smaller subset of $\mathbb{R}$.
    \begin{figure}[!ht]
        \centering\includegraphics[scale=0.4]{model_validation/prout1.png}
        \caption{ODE solution for 1,000 parameter values sampled from the prior ($\boldsymbol{\theta} \in \mathbb{R}^1$)}
        \label{fig:ppc_1}
    \end{figure}

\subsubsection{Fake Data Check}
Each fake growth curve was generated by sampling a value of $\theta$ from the prior distribution, and then simulating the tumour growth in the same way as for the Prior Predictive Check. However, as biological data is always noisy, we also added some noise to make the fake dataset closer to what we would actually expect from the labs. This was done in two different ways, resulting in two distinct datasets. For dataset~A, we simply added a white standard Gaussian noise to the simulation. For dataset B, we use added white noise to the log of the simulated curve (i.e. multiplicative noise). Using a standard Gaussian would result in too large noise values, so we chose a standard deviation of 0.3 to achieve similar levels of noise compared to datasete A. The generation process is summarized in Table~\ref{tbl:genproc}, where $x_*$ denotes a noiseless data point. The reason for using two different noise generation is that we observed, in the experimental data from the labs, that data points are usually more dispersed when they have a high value, suggesting an exponential relationship.\\ 
Additionally, each dataset contains 10 time series. Fig.~\ref{fig:fd_1} plots the fake data points against the original curve. For clarity, only 5 time series, selected at random, were shown.\\
\begin{table}[h!]
    \centering
    \caption{Summary of the generation process for the two datasets A and B}
    % \vspace{3pt}
    \begin{tabular}{c|c}
        \hline
        Dataset & Generation Process \\ \hline 
        A       & $x_A=x_*+\mathcal{N}(0,1)$ \\
        B       & $x_B=x_*\times e^{\mathcal{N}(0,\hspace{1.5px}0.3)}$ \\ \hline
    \end{tabular}
    \label{tbl:genproc}
\end{table}
\begin{figure}[!h]
    \centering
    \begin{subfigure}{.5\linewidth}
        \centering\includegraphics[scale=0.4]{model_validation/fd_1.png}
        \caption{Dataset A}
    \end{subfigure}%
    \begin{subfigure}{.5\linewidth}
        \centering\includegraphics[scale=0.4]{model_validation/fd_2.png}
        \caption{Dataset B}
    \end{subfigure}
    \caption{Plot of the fake data points (colored lines and scatter plot) along with the original growth curve (dashed line)}
    \label{fig:fd_1}
\end{figure}

\textit{Results}\\[5pt] 
Before checking if the estimated values match the true ones, we first assess convergence of the MCMC chains. Th $\hat{R}$ values (see Section~\ref{sec:eval}) are reported in Table.~\ref{tbl:rhat_2} as the average $\hat{R}$ value accross the 3 parameters. It must be noted that often, out of the 5 chains per inference, some chains  get trapped (assessed by visual inspection). In that case, they are excluded from the $\hat{R}$ calculation, and this is reported in the ``Number of Chains'' column. If all chains are exlcuded, meaning that none of them converged, we simply report N/A.

\begin{table}[!h]
    \centering
    \caption{Assessement of convergence for the MCMC chains for uninformative priors (3 free parameters)}
    \begin{tabular}{c|c||c|c|c}
        \hline
        Data set & Pooling Type & $\hat{R}$ diagnostic & Number of Chains & Convergence  \\ \hline 
        \multirow{2}{*}{A}      & None     & 116.08 & N/A & No \\
                                & Complete & 298.67 & N/A & No \\ \hline 
        \multirow{2}{*}{B}      & None     & 1.092  & 3/5 & No \\
                                & Complete & 3.11   & N/A & No \\ \hline 
    \end{tabular}
    \label{tbl:rhat_2}
\end{table}
Looking at Table~\ref{tbl:rhat_2}, we can hence conclude that the chains did not converged, meaning that the model cannot make inference with $\boldsymbol{\theta} \in \mathbb{R}^3$ and uninformative priors. To further diagnose the model, we performed another set of inferences, except that the priors where highly informative:
\begin{align*}
    \ln(k_6) \sim \text{Cauchy}^-(\theta_{k_6}, 1) \\ 
    \ln(d_1) \sim \text{Cauchy}^+(\theta_{d_1}, 1) \\ 
    \ln(s_2) \sim \text{Cauchy}^-(\theta_{s_2}, 1) \\ 
\end{align*} 
where $\theta_x$ represent the true value of parameter $x$. Convergence of this new set of inferences is shown in Table~\ref{tbl:rhat_3}. As we can see, convergence of the MCMC chains are still very poor, even with highly informative priors centered on the true parameter values.
\begin{table}[!h]
    \centering
    \caption{Assessement of convergence for the MCMC chains for uninformative priors (3 free parameters)}
    \begin{tabular}{c|c||c|c|c}
        \hline
        Data set & Pooling Type & $\hat{R}$ diagnostic & Number of Chains & Convergence  \\ \hline 
        \multirow{2}{*}{A}      & None  & 18.15 & N/A & No \\
                                & Complete & 45.96 & N/A & No \\ \hline 
        \multirow{2}{*}{B}      & None  & 1.505 & 3/5 & No \\
                                & Complete & 1.014 & 2/5 & Yes \\ \hline 
    \end{tabular}
    \label{tbl:rhat_3}
\end{table}
\\[12pt]
It might be objected that Cauchy distributions are by definition not too informative since a non-negligible portion of their mass stretches well beyond their standard deviation, contrary to normal distributions. This hence motivated us to perform one last fake data check, using the normal priors shown below to be even more informative: 
\begin{align*}
    \ln(k_6) \sim \mathcal{N}^-(\theta_{k_6}, 0.3) \\ 
    \ln(d_1) \sim \mathcal{N}^+(\theta_{d_1}, 0.3) \\ 
    \ln(s_2) \sim \mathcal{N}^-(\theta_{s_2}, 0.3) \\ 
\end{align*}
Convergence results are shown in Table.~\ref{tbl:rhat_4}. The main result is that chains converged or were close to convergence only for dataset D, showing that a log-normal transformation is key to make exploration of the posterior easier to perform. Whilst the overall convergence rate is still very low given the informative normal priors, this series of fake data checks for the case of three free parameters highlighted the key role of the log-transformation.

\begin{table}[!h]
    \centering
    \caption{Assessement of convergence for the MCMC chains for uninformative priors (3 free parameters)}
    \begin{tabular}{c|c||c|c|c}
        \hline
        Data set & Pooling Type & $\hat{R}$ diagnostic & Number of Chains & Convergence  \\ \hline 
        \multirow{2}{*}{A}      & None     & 7.387 & N/A & No \\
                                & Complete & 39.17 & N/A & No \\ \hline 
        \multirow{2}{*}{B}      & None     & 1.066 & 3/5 & Yes \\
                                & Complete & 1.111 & 5/5 & No \\ \hline 
    \end{tabular}
    \label{tbl:rhat_4}
\end{table}
~\\
\textit{Conclusion}\\[5pt]
Even with informative priors, the MCMC chains do not even converge. This suggests that the likelihood function is too difficult to explore and might contain discontinuities. As suggested by Gelman et al. (2020) in their \textit{Bayesian Workflow} document, the first step to take to address this issue would be to drastically simplify the likelihood function and re-assess performance of the model of fake datasets. Another approach that we are currently exploring would be to use Approximate Bayesian Computation. These two approaches will enable us to further diagnose the model to make appropriate corrections.


\section{Implementation Plan}\label{sec:plan}

\begin{figure}[!ht]
    \centering\includegraphics[scale=0.32]{gantt.png}
\end{figure}

\clearpage
\newpage
\appendix
\section{Parameters of the Computational Model}\label{app}
\begin{table}[!h]
    \centering
    \caption{Parameters of Miyano's model along with their description}
    \begin{tabular}{c |l}
        \hline 
        Parameter & Description \\ \hline
        $t_{delay}$ & time delay from injection timiring to deliver CBD-IL-12 to tumour \\ 
        $t_{last}$ & time duration of drug effects of CBD-IL-12 \\ 
        $t_{delay12}$ & time delay from injection timing to deliver IL-12 to tumour \\
        $t_{last12}$ & time duration of drug effects of IL-12 \\ 
        $t_d$ & time delay for producing $CD8^+$ via IFN$\gamma$ \\ \hdashline
        $k_1$ & production rate of IFN$\gamma$ via unspecified pathways \\ 
        $k_2$ & production rate of IFN$\gamma$ via CBD-IL-12 \\ 
        $k_3$ & production rate pf CD8$^+$ via unspecified pathways \\ 
        $k_4$ & production rate of CD8$^+$ via IFN$\gamma$ \\ 
        $k_5$ & production rate of PD-1 via unspecified pathways \\ 
        $k_6$ & proliferation rate of tumour \\ \hdashline
        $d_1$ & elimination rate of IFN$\gamma$ via turnover \\
        $d_2$ & elimination rate of CD8$^+$ via turnover \\ 
        $d_3$ & elimination rate of PD-1 via turnover  \\ 
        $d_4$ & elimination rate of PD-1 via turnover IFN$\gamma$ \\ 
        $d_5$ & elimination rate of living tumour via turnover \\ 
        $d_6$ & elimination rate of living tumour via CD8$^+$ \\ 
        $d_7$ & elimination rate of living tumour via IFN$\gamma$ \\ 
        $d_8$ & elimination rate of dead tumour via turnover \\\hdashline
        $s_1$ & inhibition strength of PD-1 on anti-tumour effects of CDB$^+$ \\ 
        $s_2$ & inhibition strength of tumour volume on antitumour effects of IFN$\gamma$ and CD8$^+$ cells \\ \hline
    \end{tabular}
\end{table}

\clearpage
\newpage

\addcontentsline{toc}{section}{References}
\bibliographystyle{unsrt}
\bibliography{biblio}


\end{document} % This is the end of the document

%% Trash-city

% The goal of immunotherapy is to use a specific type of cytotoxic immune cells, the CD8$^+$ cells, to fight against cancer \cite{ReviewCPI}. As cancer can escape these killer cells through various mechanisms, this lead to a range of difference 

% While all cancer immunotherapies focus on using the natural immune system to fight against cancer, many different variations exist. The specific therapy of concern in this project is a combination of cytokine-based treatments and immune checkpoint inhibitors. Before explaining its specificities in more details, we will review the general principles behind the two aforementionned types of immunotherapy. In both case, a specific type of T-lymphocyte, the CD8$^+$ T-cells, is the central actor . CD8$^+$ differentiate itself from other T-cells through the expression of the membrane receptor CD8, and its main function is to directly carry out cytotoxic activity (i.e. killing the malignant cells) after detecting tumoural antigen~\cite{cd8Effects}.
%

% it is a pleiotropic molecule, meaning that it results in the release of numerous cytokines throughout the immune response~\cite{il12CytokineStorm}. One particular molecule released during this cytokine storm is the interferon-$\gamma$ (IFN$\gamma$). IFN$\gamma$ plays a dominant role within this cytokine storm, as not only does it have anti-angiogenesis effect~\cite{ifngAngiogenesis}, thus limiting cancer growth; but it also stimulate production Natural Killer cells \cite{ifngNKProd} (another type of cytotoxic cells capable of attacking tumours) and upregulate antigen-presenting pathways within tumour cells \cite{ifngAntigenExposure}. Finally, IL-12 facilitates T-cell proliferation by reducing negative regulatory pathways that lead to immunosuppression. Indeed, IL-12 inhibts the effect of the immune checkpoint PD-1, similarly to chekpoint inhibitors (CPI) treatments \cite{reducImmunoSuppression}. The more details mode of action is described in the following paragraph. [maybe need to mention trAEs? and poor performance so far...]
%
